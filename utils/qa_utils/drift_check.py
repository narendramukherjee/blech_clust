"""
Check for drift in firing rate across the session.

1) Check using ANOVA across quarters of the session
2) Generate plots of firing rate across the session for each unit

**NOTE**: Do not worry about opto trials for now. Assuming opto trials
are well ditributed across the session, they should not affect the
mean firing rate.
"""

# Import stuff!
import numpy as np
import tables
import sys
import os
import matplotlib
import pylab as plt
from scipy.stats import zscore
import pandas as pd
import pingouin as pg
import seaborn as sns
import glob
# Get script path
script_path = os.path.dirname(os.path.realpath(__file__))
blech_path = os.path.dirname(os.path.dirname(script_path))
sys.path.append(blech_path)
from utils.blech_utils import imp_metadata

def get_spike_trains(hf5_path):
    """
    Get spike trains from hdf5 file

    Inputs:
        hf5_path: path to hdf5 file

    Outputs:
        spike_trains: list of spike trains (trials, units, time)
    """
    with tables.open_file(hf5_path, 'r') as hf5:
        # Get the spike trains
        dig_ins = hf5.list_nodes('/spike_trains') 
        dig_in_names = [dig_in._v_name for dig_in in dig_ins]
        spike_trains = [x.spike_array[:] for x in dig_ins]
    return spike_trains

def array_to_df(array, dim_names):
    """
    Convert array to dataframe with dimensions as columns

    Inputs:
        array: array to convert
        dim_names: list of names for each dimension

    Outputs:
        df: dataframe with dimensions as columns
    """
    assert len(dim_names) == array.ndim, 'Number of dimensions does not match number of names'

    inds = np.array(list(np.ndindex(array.shape)))
    df = pd.DataFrame(inds, columns=dim_names)
    df['value'] = array.flatten()
    return df

############################################################
## Initialize 
############################################################
# Get name of directory with the data files
metadata_handler = imp_metadata(sys.argv)
dir_name = metadata_handler.dir_name


# dir_name = '/home/abuzarmahmood/Desktop/blech_clust/pipeline_testing/test_data_handling/test_data/KM45_5tastes_210620_113227_new/'
# metadata_handler = imp_metadata([[], dir_name])
# dir_name = metadata_handler.dir_name

os.chdir(dir_name)
print(f'Processing : {dir_name}')

basename = os.path.basename(dir_name[:-1])

output_dir = os.path.join(dir_name, 'QA_output')
if not os.path.isdir(output_dir):
    os.mkdir(output_dir)

warnings_file_path = os.path.join(output_dir, 'warnings.txt')

############################################################
## Load Data
############################################################
# Open the hdf5 file
spike_trains = get_spike_trains(metadata_handler.hdf5_name)

############################################################
## Perform Processing 
############################################################

##############################
## Plot firing rate across session
##############################
# Flatten out spike trains for each taste
unit_spike_trains = [np.swapaxes(x, 0, 1) for x in spike_trains]
long_spike_trains = [x.reshape(x.shape[0],-1) for x in unit_spike_trains]

# Bin data to plot
bin_size = 1000
binned_spike_trains = [np.reshape(x, (x.shape[0], -1, bin_size)).sum(axis=2) for x in long_spike_trains]

# Group by neuron across tastes
plot_spike_trains = list(zip(*binned_spike_trains))
zscore_binned_spike_trains = [zscore(x, axis=-1) for x in plot_spike_trains]

# Plot heatmaps of all tastes, both raw data and zscored
fig, ax = plt.subplots(len(plot_spike_trains), 2, figsize=(10, 10))
for i in range(len(plot_spike_trains)):
    ax[i, 0].imshow(plot_spike_trains[i], aspect='auto', interpolation='none')
    ax[i, 1].imshow(zscore_binned_spike_trains[i], aspect='auto', interpolation='none')
    ax[i, 0].set_title(f'Unit {i+1} Raw')
    ax[i, 1].set_title(f'Unit {i+1} Zscored')
    ax[i, 0].set_ylabel('Taste')
fig.suptitle('Binned Spike Heatmaps \n' + basename + '\n' + 'Bin Size: ' + str(bin_size) + ' ms')
plt.tight_layout()
plt.savefig(os.path.join(output_dir, 'binned_spike_heatmaps.png'))
plt.close()

##############################
## Perform ANOVA on baseline and post-stimulus firing rates separately
##############################
alpha = 0.05

n_trial_bins = 4
stim_t = metadata_handler.params_dict['spike_array_durations'][0]
baseline_duration = 1000 # Take period from stim_t - baseline_duration to stim_t
trial_duration = 2500 # Take period from stim_t to stim_t + trial_duration

##############################
# Baseline

# For baseline, check across trials and tastes both
baseline_spike_trains = [x[...,stim_t-baseline_duration:stim_t] for x in spike_trains]
baseline_counts = [x.sum(axis=-1) for x in baseline_spike_trains]
baseline_counts_df_list = [array_to_df(x, ['trial', 'unit']) for x in baseline_counts]
# Add taste column
for i in range(len(baseline_counts_df_list)):
    baseline_counts_df_list[i]['taste'] = i
# Add indicator for trial bins 
for i in range(len(baseline_counts_df_list)):
    baseline_counts_df_list[i]['trial_bin'] = pd.cut(baseline_counts_df_list[i]['trial'], n_trial_bins, labels=False) 
baseline_counts_df = pd.concat(baseline_counts_df_list, axis=0)

# Plot baseline firing rates
g = sns.catplot(data=baseline_counts_df, 
            x='trial_bin', y='value', 
            row='taste', col = 'unit', 
            kind='bar', sharey=False,
                )
fig = plt.gcf()
fig.suptitle('Baseline Firing Rates \n' +\
        basename + '\n' +\
        'Trial Bin Count: ' + str(n_trial_bins) + '\n' +\
        'Baseline limits: ' + str(stim_t-baseline_duration) + ' to ' + str(stim_t) + ' ms') 
plt.tight_layout()
plt.savefig(os.path.join(output_dir, 'baseline_firing_rates.png'))
plt.close()

# Perform 2-way ANOVA on baseline firing rates across trial bins and tastes
grouped_list = baseline_counts_df.groupby('unit')
group_ids = [x[0] for x in grouped_list]
group_dat = [x[1] for x in grouped_list]
anova_out = [pg.anova(data=x, dv='value', between=['trial_bin', 'taste'], detailed=True) for x in group_dat]

p_vals = [x[['Source','p-unc']] for x in anova_out]
# Set source as index
for i in range(len(p_vals)):
    p_vals[i].set_index('Source', inplace=True)
# Transpose and add unit column
p_vals = [x.T for x in p_vals]
for i in range(len(p_vals)):
    p_vals[i]['unit'] = group_ids[i]
# Concatenate into single dataframe
p_val_frame = pd.concat(p_vals, axis=0)
p_val_frame.reset_index(inplace=True, drop=True)

# Output p-values
p_val_frame.to_csv(os.path.join(output_dir, 'baseline_drift_p_vals.csv'))

# Generate a plot of the above array marking significant p-values
# First, get the p-values
wanted_cols = ['trial_bin','taste','trial_bin * taste']
p_val_mat = p_val_frame[wanted_cols].values
# Then, get the significant p-values
sig_p_val_mat = p_val_mat < alpha 
# Plot the significant p-values
fig, ax = plt.subplots(figsize=(10, 10))
ax.imshow(sig_p_val_mat, aspect='auto', interpolation='none', cmap='gray')
ax.set_xticks(np.arange(len(wanted_cols)))
ax.set_yticks(np.arange(len(group_ids)))
ax.set_xticklabels(wanted_cols)
ax.set_yticklabels(group_ids)
ax.set_title('Significant p-values for 2-way ANOVA on Baseline Firing Rates')
ax.set_xlabel('Comparison Type')
ax.set_ylabel('Unit')
# Add p-values to plot
for i in range(len(group_ids)):
    for j in range(len(wanted_cols)):
        this_str_color = 'k' if sig_p_val_mat[i, j] else 'w'
        ax.text(j, i, str(round(p_val_mat[i, j],3)), 
                ha='center', va='center', color=this_str_color)
plt.savefig(os.path.join(output_dir, 'baseline_drift_p_val_heatmap.png'))
plt.close()

# If any significant p-values, write to warning file
if np.any(sig_p_val_mat):
    out_rows_inds = np.any(sig_p_val_mat, axis=1)
    out_rows = p_val_frame.iloc[out_rows_inds]

    with open(warnings_file_path, 'a') as f:
        print('=== Baseline Drift Warning ===', file=f)
        print('2-way ANOVA on baseline firing rates across trial bins and tastes', file=f)
        print('Baseline limits: ' + str(stim_t-baseline_duration) + ' to ' + str(stim_t) + ' ms', file=f)
        print('Trial Bin Count: ' + str(n_trial_bins), file=f)
        print('alpha: ' + str(alpha), file=f)
        print('\n', file=f)
        print(out_rows, file=f)
        print('\n', file=f)
        print('=== End Baseline Drift Warning ===', file=f)
        print('\n', file=f)



##############################
# Post-stimulus 

# For post-stimulus, check across trials only
post_spike_trains = [x[...,stim_t:stim_t+trial_duration] for x in spike_trains]
post_counts = [x.sum(axis=-1) for x in post_spike_trains]
post_counts_df_list = [array_to_df(x, ['trial', 'unit']) for x in post_counts]
# Add taste column
for i in range(len(post_counts_df_list)):
    post_counts_df_list[i]['taste'] = i
# Add indicator for trial bins
for i in range(len(post_counts_df_list)):
    post_counts_df_list[i]['trial_bin'] = pd.cut(post_counts_df_list[i]['trial'], n_trial_bins, labels=False)
post_counts_df = pd.concat(post_counts_df_list, axis=0)

# Plot post-stimulus firing rates
g = sns.catplot(data=post_counts_df,
            x='trial_bin', y='value',
            col = 'unit', hue='taste',
            kind='bar', sharey=False,
                )
fig = plt.gcf()
fig.suptitle('Post-stimulus Firing Rates \n' +\
        basename + '\n' +\
        'Trial Bin Count: ' + str(n_trial_bins) + '\n' +\
        'Post-stimulus limits: ' + str(stim_t) + ' to ' + str(stim_t+trial_duration) + ' ms')
plt.tight_layout()
plt.savefig(os.path.join(output_dir, 'post_firing_rates.png'))
plt.close()

# Perform repeated measures ANOVA on post-stimulus firing rates across trial bins 
# Taste is the repeated measure

grouped_list = post_counts_df.groupby('unit')
group_ids = [x[0] for x in grouped_list]
group_dat = [x[1] for x in grouped_list]
anova_out = [pg.rm_anova(data=x, dv='value', within='trial_bin', subject='taste', detailed=True) for x in group_dat]

p_vals = [x[['Source','p-unc']] for x in anova_out]
# Set source as index
for i in range(len(p_vals)):
    p_vals[i].set_index('Source', inplace=True)
# Transpose and add unit column
p_vals = [x.T for x in p_vals]
for i in range(len(p_vals)):
    p_vals[i]['unit'] = group_ids[i]
# Concatenate into single dataframe
p_val_frame = pd.concat(p_vals, axis=0)
p_val_frame.reset_index(inplace=True, drop=True)

# Output p-values
p_val_frame.to_csv(os.path.join(output_dir, 'post_drift_p_vals.csv'))

# Generate a plot of the above array marking significant p-values
# First, get the p-values
p_val_vec = p_val_frame['trial_bin'].values
# Then, get the significant p-values
sig_p_val_vec = p_val_vec < 0.05
# Then generate figure
plt.figure()
plt.imshow(sig_p_val_vec.reshape((1,-1)), cmap='gray')
plt.title('Significant p-values')
plt.xlabel('Unit')
plt.ylabel('Trial Bin')
# Add unit labels
plt.xticks(np.arange(len(group_ids)), group_ids)
# Add p-values to plot
for i in range(len(p_val_vec)):
    this_str_color = 'black' if sig_p_val_vec[i] else 'white'
    plt.text(i, 0, str(round(p_val_vec[i],3)), 
             horizontalalignment='center', verticalalignment='center',
             color=this_str_color)
plt.savefig(os.path.join(output_dir, 'post_drift_p_vals.png'))
plt.close()

# If any significant p-values, write to warning file
if np.any(sig_p_val_vec):
    out_rows_inds = sig_p_val_vec
    out_rows = p_val_frame.iloc[out_rows_inds]

    with open(warnings_file_path, 'a') as f:
        print('=== Post-stimulus Warning ===', file=f)
        print('Repeated measures ANOVA on post-stimulus firing rates across trial bins and tastes', file=f)
        print('Post-stimulus limits: ' + str(stim_t) + ' to ' + str(stim_t+trial_duration) + ' ms', file=f)
        print('Trial Bin Count: ' + str(n_trial_bins), file=f)
        print('alpha: ' + str(alpha), file=f)
        print('\n', file=f)
        print(out_rows, file=f)
        print('\n', file=f)
        print('=== End Post-stimulus Warning ===', file=f)
        print('\n', file=f)
